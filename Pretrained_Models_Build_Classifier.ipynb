{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "id": "cYy9gbg9_N9u",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "id": "t3s6ONqc_N9w",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "In this lab, you will learn how to leverage pre-trained models to build image classifiers instead of building a model from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "id": "uSYTsnN0_N9x",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Table of Contents\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "\n",
    "<font size = 3> \n",
    "    \n",
    "1. <a href=\"#item31\">Import Libraries and Packages</a>\n",
    "2. <a href=\"#item32\">Download Data</a>  \n",
    "3. <a href=\"#item33\">Define Global Constants</a>  \n",
    "4. <a href=\"#item34\">Construct ImageDataGenerator Instances</a>  \n",
    "5. <a href=\"#item35\">Compile and Fit Model</a>\n",
    "\n",
    "</font>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "id": "EpwlLYg9_N9y",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "id": "WzDc2Ea1_N90",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id='item31'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "id": "Hc6dtXJj_N91",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Import Libraries and Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "id": "O4xn07ZY_N92",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Let's start the lab by importing the libraries that we will be using in this lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "id": "BNR1XE-i_N93",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "First, we will import the ImageDataGenerator module since we will be leveraging it to train our model in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "button": false,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2706,
     "status": "ok",
     "timestamp": 1589612321371,
     "user": {
      "displayName": "Kota sai durga kamesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjTjqAs_XSPRluT1e_1a161LYmq1xxzr4Q-wY37=s64",
      "userId": "02067056678749702267"
     },
     "user_tz": -330
    },
    "id": "OBOt1VTq_N95",
    "new_sheet": false,
    "outputId": "f77e6884-3589-4c52-ab1e-1538d092a861",
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "id": "4HjLYVZU_N-B",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "In this lab, we will be using the Keras library to build an image classifier, so let's download the Keras library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "button": false,
    "colab": {},
    "colab_type": "code",
    "id": "pnJNX7vN_N-C",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "id": "5k-wFdoU_N-H",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Finally, we will be leveraging the ResNet50 model to build our classifier, so let's download it as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "button": false,
    "colab": {},
    "colab_type": "code",
    "id": "xSacTiqL_N-H",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from keras.applications import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "id": "oqOkVgcu_N-L",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id='item32'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "id": "xCY1reYN_N-Q",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Download Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "id": "RY4VhnPA_N-R",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "For your convenience, I have placed the data on a server which you can retrieve easily using the **wget** command. So let's run the following line of code to get the data. Given the large size of the image dataset, it might take some time depending on your internet speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "button": false,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14224,
     "status": "ok",
     "timestamp": 1589612338248,
     "user": {
      "displayName": "Kota sai durga kamesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjTjqAs_XSPRluT1e_1a161LYmq1xxzr4Q-wY37=s64",
      "userId": "02067056678749702267"
     },
     "user_tz": -330
    },
    "id": "E8W4hw6y_N-S",
    "new_sheet": false,
    "outputId": "634e7305-c6d0-4403-e36f-995f728e108a",
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-05-16 06:58:53--  https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/concrete_data_week3.zip\n",
      "Resolving s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)... 67.228.254.196\n",
      "Connecting to s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)|67.228.254.196|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 261482368 (249M) [application/zip]\n",
      "Saving to: ‘concrete_data_week3.zip’\n",
      "\n",
      "concrete_data_week3 100%[===================>] 249.37M  33.5MB/s    in 8.2s    \n",
      "\n",
      "2020-05-16 06:59:02 (30.4 MB/s) - ‘concrete_data_week3.zip’ saved [261482368/261482368]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## get the data\n",
    "!wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/concrete_data_week3.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "id": "a1JZ-_6C_N-W",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "And now if you check the left directory pane, you should see the zipped file *concrete_data_week3.zip* appear. So, let's go ahead and unzip the file to access the images. Given the large number of images in the dataset, this might take a couple of minutes, so please be patient, and wait until the code finishes running."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "id": "t-prrqCX_N-d",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Now, you should see the folder *concrete_data_week3* appear in the left pane. If you open this folder by double-clicking on it, you will find that it contains two folders: *train* and *valid*. And if you explore these folders, you will find that each contains two subfolders: *positive* and *negative*. These are the same folders that we saw in the labs in the previous modules of this course, where *negative* is the negative class and it represents the concrete images with no cracks and *positive* is the positive class and it represents the concrete images with cracks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip concrete_data_week3.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "id": "2U-3gh35_N-d",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "**Important Note**: There are thousands and thousands of images in each folder, so please don't attempt to double click on the *negative* and *positive* folders. This may consume all of your memory and you may end up with a **50*** error. So please **DO NOT DO IT**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "id": "3sIsk94q_N-e",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id='item33'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "id": "hHrHKI2U_N-f",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Define Global Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "id": "FVnrWMn__N-f",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Here, we will define constants that we will be using throughout the rest of the lab. \n",
    "\n",
    "1. We are obviously dealing with two classes, so *num_classes* is 2. \n",
    "2. The ResNet50 model was built and trained using images of size (224 x 224). Therefore, we will have to resize our images from (227 x 227) to (224 x 224).\n",
    "3. We will training and validating the model using batches of 100 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "button": false,
    "colab": {},
    "colab_type": "code",
    "id": "QbbZZKRl_N-g",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "\n",
    "image_resize = 224\n",
    "\n",
    "batch_size_training = 100\n",
    "batch_size_validation = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "id": "-w05vmWw_N-j",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id='item34'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "id": "MxwmKbVM_N-j",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Construct ImageDataGenerator Instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "id": "dcvrQnfL_N-k",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "In order to instantiate an ImageDataGenerator instance, we will set the **preprocessing_function** argument to *preprocess_input* which we imported from **keras.applications.resnet50** in order to preprocess our images the same way the images used to train ResNet50 model were processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "button": false,
    "colab": {},
    "colab_type": "code",
    "id": "z6yosXbm_N-l",
    "jupyter": {
     "outputs_hidden": true
    },
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "id": "-CJg8dao_N-o",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Next, we will use the *flow_from_directory* method to get the training images as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "button": false,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2613,
     "status": "ok",
     "timestamp": 1589614016622,
     "user": {
      "displayName": "Kota sai durga kamesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjTjqAs_XSPRluT1e_1a161LYmq1xxzr4Q-wY37=s64",
      "userId": "02067056678749702267"
     },
     "user_tz": -330
    },
    "id": "gusdiWI__N-o",
    "jupyter": {
     "outputs_hidden": true
    },
    "new_sheet": false,
    "outputId": "a0efd72f-f5c9-4288-8c28-20b41f356101",
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30001 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = data_generator.flow_from_directory(\n",
    "    'concrete_data_week3/train',\n",
    "    target_size=(image_resize, image_resize),\n",
    "    batch_size=batch_size_training,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "id": "Cf5ZKeef_N-s",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "**Your Turn**: Use the *flow_from_directory* method to get the validation images and assign the result to **validation_generator**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "button": false,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1246,
     "status": "ok",
     "timestamp": 1589614020734,
     "user": {
      "displayName": "Kota sai durga kamesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjTjqAs_XSPRluT1e_1a161LYmq1xxzr4Q-wY37=s64",
      "userId": "02067056678749702267"
     },
     "user_tz": -330
    },
    "id": "O8y9m2p9_N-t",
    "jupyter": {
     "outputs_hidden": true
    },
    "new_sheet": false,
    "outputId": "854fecf4-e66c-4964-a77b-56f1102ef986",
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10001 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "validation_generator=data_generator.flow_from_directory('concrete_data_week3/valid',target_size=(224,224),batch_size=100,class_mode='categorical')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "id": "c9v_K9Nf_N-w",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id='item35'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "id": "znduNLqO_N-x",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Build, Compile and Fit Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "id": "g9COmcwz_N-y",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "In this section, we will start building our model. We will use the Sequential model class from Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "button": false,
    "colab": {},
    "colab_type": "code",
    "id": "nakUmsXI_N-y",
    "jupyter": {
     "outputs_hidden": true
    },
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "id": "Eg0jT8uN_N-2",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Next, we will add the ResNet50 pre-trained model to out model. However, note that we don't want to include the top layer or the output layer of the pre-trained model. We actually want to define our own output layer and train it so that it is optimized for our image dataset. In order to leave out the output layer of the pre-trained model, we will use the argument *include_top* and set it to **False**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "button": false,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 19741,
     "status": "ok",
     "timestamp": 1589614045423,
     "user": {
      "displayName": "Kota sai durga kamesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjTjqAs_XSPRluT1e_1a161LYmq1xxzr4Q-wY37=s64",
      "userId": "02067056678749702267"
     },
     "user_tz": -330
    },
    "id": "djr_UC8b_N-3",
    "jupyter": {
     "outputs_hidden": true
    },
    "new_sheet": false,
    "outputId": "24e9a42a-f580-4546-ad09-b6e1773fdd0f",
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94658560/94653016 [==============================] - 3s 0us/step\n"
     ]
    }
   ],
   "source": [
    "model.add(ResNet50(\n",
    "    include_top=False,\n",
    "    pooling='avg',\n",
    "    weights='imagenet',\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "id": "Mro-2AjU_N--",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Then, we will define our output layer as a **Dense** layer, that consists of two nodes and uses the **Softmax** function as the activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "button": false,
    "colab": {},
    "colab_type": "code",
    "id": "fVo3WPBA_N-_",
    "jupyter": {
     "outputs_hidden": true
    },
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "id": "u10T-Lse_N_C",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "You can access the model's layers using the *layers* attribute of our model object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "button": false,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 18981,
     "status": "ok",
     "timestamp": 1589614045425,
     "user": {
      "displayName": "Kota sai durga kamesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjTjqAs_XSPRluT1e_1a161LYmq1xxzr4Q-wY37=s64",
      "userId": "02067056678749702267"
     },
     "user_tz": -330
    },
    "id": "_BSsLhKP_N_D",
    "jupyter": {
     "outputs_hidden": true
    },
    "new_sheet": false,
    "outputId": "61c11844-d2ff-4e62-ba72-f7e7ecd3c4d5",
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.training.Model at 0x7f2da02e3a90>,\n",
       " <keras.layers.core.Dense at 0x7f2da0291ba8>]"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "id": "0ksWWD4F_N_F",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "You can see that our model is composed of two sets of layers. The first set is the layers pertaining to ResNet50 and the second set is a single layer, which is our Dense layer that we defined above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "id": "AnM6gTpR_N_G",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "You can access the ResNet50 layers by running the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "button": false,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15783,
     "status": "ok",
     "timestamp": 1589614045426,
     "user": {
      "displayName": "Kota sai durga kamesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjTjqAs_XSPRluT1e_1a161LYmq1xxzr4Q-wY37=s64",
      "userId": "02067056678749702267"
     },
     "user_tz": -330
    },
    "id": "ADDE3msG_N_H",
    "jupyter": {
     "outputs_hidden": true
    },
    "new_sheet": false,
    "outputId": "1be53f09-cbcd-439f-96ff-f7de048da7fe",
    "run_control": {
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x7f2db3e2e898>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x7f2db3e2e908>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f2db3e2ea90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f2db3e2eba8>,\n",
       " <keras.layers.core.Activation at 0x7f2db3e2e710>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x7f2db2d07908>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x7f2db2d074a8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f2e0d390748>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f2db2871ba8>,\n",
       " <keras.layers.core.Activation at 0x7f2db2831d68>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f2db2831cc0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f2db283c470>,\n",
       " <keras.layers.core.Activation at 0x7f2db284fd30>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f2db27ec1d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f2db27fe588>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f2db27feb70>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f2db279e438>,\n",
       " <keras.layers.merge.Add at 0x7f2db27b02e8>,\n",
       " <keras.layers.core.Activation at 0x7f2db27bdc50>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f2db27bd390>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f2db2765ba8>,\n",
       " <keras.layers.core.Activation at 0x7f2db276c908>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f2db277da20>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f2db27832b0>,\n",
       " <keras.layers.core.Activation at 0x7f2e13aad5c0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f2db2795da0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f2db3ea0940>,\n",
       " <keras.layers.merge.Add at 0x7f2db3ea0358>,\n",
       " <keras.layers.core.Activation at 0x7f2db2746b00>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f2db2746be0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f2db26e0a20>,\n",
       " <keras.layers.core.Activation at 0x7f2db26e72b0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f2db26f1358>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f2db2702c18>,\n",
       " <keras.layers.core.Activation at 0x7f2db2702630>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f2db269ec88>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f2db26a6438>,\n",
       " <keras.layers.merge.Add at 0x7f2db26b6da0>,\n",
       " <keras.layers.core.Activation at 0x7f2db26d0668>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f2db26d0748>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f2db2665d68>,\n",
       " <keras.layers.core.Activation at 0x7f2db2672d68>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f2db2682ef0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f2db2699780>,\n",
       " <keras.layers.core.Activation at 0x7f2db2699198>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f2db26374e0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f2db264fa90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f2db264aef0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f2db25ed7f0>,\n",
       " <keras.layers.merge.Add at 0x7f2db25ff7b8>,\n",
       " <keras.layers.core.Activation at 0x7f2db260bd68>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f2db260b978>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f2db22bd208>,\n",
       " <keras.layers.core.Activation at 0x7f2db22ce0b8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f2db22de0f0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f2db226e9b0>,\n",
       " <keras.layers.core.Activation at 0x7f2db226e3c8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f2db228c710>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f2db22951d0>,\n",
       " <keras.layers.merge.Add at 0x7f2db22a5cc0>,\n",
       " <keras.layers.core.Activation at 0x7f2db223bf60>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f2db223bef0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f2db2258da0>,\n",
       " <keras.layers.core.Activation at 0x7f2db225fb00>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f2db21edcf8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f2db21f64a8>,\n",
       " <keras.layers.core.Activation at 0x7f2db2206e10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f2db2222278>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f2db21b6dd8>,\n",
       " <keras.layers.merge.Add at 0x7f2db21bcef0>,\n",
       " <keras.layers.core.Activation at 0x7f2db21d3ef0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f2db21d3fd0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f2db2171e48>,\n",
       " <keras.layers.core.Activation at 0x7f2db21786d8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f2db2186780>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f2db2199f28>,\n",
       " <keras.layers.core.Activation at 0x7f2db219fb00>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f2db2135d68>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f2db214e8d0>,\n",
       " <keras.layers.merge.Add at 0x7f2db214e2e8>,\n",
       " <keras.layers.core.Activation at 0x7f2db2165a90>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f2db2165b70>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f2db210a9b0>,\n",
       " <keras.layers.core.Activation at 0x7f2db2112240>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f2db211f2e8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f2db20b1ba8>,\n",
       " <keras.layers.core.Activation at 0x7f2db20b15c0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f2db20d0908>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f2db2068d30>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f2db20d53c8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f2db2097cf8>,\n",
       " <keras.layers.merge.Add at 0x7f2db2097be0>,\n",
       " <keras.layers.core.Activation at 0x7f2db20a2d68>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f2db20a2da0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f2db204fbe0>,\n",
       " <keras.layers.core.Activation at 0x7f2db20574e0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f2db2065518>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f2db1ffa7f0>,\n",
       " <keras.layers.core.Activation at 0x7f2db1ffff60>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f2db2016ef0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f2db1fae668>,\n",
       " <keras.layers.merge.Add at 0x7f2db1faef60>,\n",
       " <keras.layers.core.Activation at 0x7f2db1fc8828>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f2db1fc8908>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f2db1fe1198>,\n",
       " <keras.layers.core.Activation at 0x7f2db1fe7f60>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f2db1f81080>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f2db1f92940>,\n",
       " <keras.layers.core.Activation at 0x7f2db1f92358>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f2db1f316a0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f2db1f36278>,\n",
       " <keras.layers.merge.Add at 0x7f2db1f47c50>,\n",
       " <keras.layers.core.Activation at 0x7f2db1f5df98>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f2db1f5df60>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f2db1efcd30>,\n",
       " <keras.layers.core.Activation at 0x7f2db1f01a90>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f2db1f11c88>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f2db1f19438>,\n",
       " <keras.layers.core.Activation at 0x7f2db1eabda0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f2db1ec62b0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f2db1edad68>,\n",
       " <keras.layers.merge.Add at 0x7f2db1edffd0>,\n",
       " <keras.layers.core.Activation at 0x7f2db1e76eb8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f2db1e76f98>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f2db1e96dd8>,\n",
       " <keras.layers.core.Activation at 0x7f2db1e9d8d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f2db1e2a710>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f2db1e3def0>,\n",
       " <keras.layers.core.Activation at 0x7f2db1e45a90>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f2db1e5df98>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f2db1df4860>,\n",
       " <keras.layers.merge.Add at 0x7f2db1df4278>,\n",
       " <keras.layers.core.Activation at 0x7f2db1e0fa20>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f2db1e0fb00>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f2db1da8160>,\n",
       " <keras.layers.core.Activation at 0x7f2db1db5ac8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f2db1dc3278>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f2db1dd6b38>,\n",
       " <keras.layers.core.Activation at 0x7f2db1dd6550>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f2da04b5898>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f2da04bc358>,\n",
       " <keras.layers.merge.Add at 0x7f2da04cfe48>,\n",
       " <keras.layers.core.Activation at 0x7f2da046b588>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f2da046b668>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f2da0485f28>,\n",
       " <keras.layers.core.Activation at 0x7f2da0488c88>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f2da049af28>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f2da04316a0>,\n",
       " <keras.layers.core.Activation at 0x7f2da04311d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f2da044f400>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f2da0466a90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f2da0460908>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f2da0404710>,\n",
       " <keras.layers.merge.Add at 0x7f2da04156d8>,\n",
       " <keras.layers.core.Activation at 0x7f2da0421780>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f2da0421828>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f2da03caeb8>,\n",
       " <keras.layers.core.Activation at 0x7f2da03cff28>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f2da03e0fd0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f2da03788d0>,\n",
       " <keras.layers.core.Activation at 0x7f2da03782e8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f2da0396630>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f2da039c6d8>,\n",
       " <keras.layers.merge.Add at 0x7f2da032dbe0>,\n",
       " <keras.layers.core.Activation at 0x7f2da0345f98>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f2da0345e48>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f2da0362cc0>,\n",
       " <keras.layers.core.Activation at 0x7f2da0369a20>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f2da02fab38>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f2da02fe3c8>,\n",
       " <keras.layers.core.Activation at 0x7f2da0312d30>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7f2da02ae240>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7f2da02c0c88>,\n",
       " <keras.layers.merge.Add at 0x7f2da02c06a0>,\n",
       " <keras.layers.core.Activation at 0x7f2da02dee48>,\n",
       " <keras.layers.pooling.GlobalAveragePooling2D at 0x7f2da02def28>]"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "id": "fKz5FISR_N_K",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Since the ResNet50 model has already been trained, then we want to tell our model not to bother with training the ResNet part, but to train only our dense output layer. To do that, we run the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "button": false,
    "colab": {},
    "colab_type": "code",
    "id": "yNnCp2db_N_K",
    "jupyter": {
     "outputs_hidden": true
    },
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "id": "Q0reVBfc_N_N",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "And now using the *summary* attribute of the model, we can see how many parameters we will need to optimize in order to train the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "button": false,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14967,
     "status": "ok",
     "timestamp": 1589614045427,
     "user": {
      "displayName": "Kota sai durga kamesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjTjqAs_XSPRluT1e_1a161LYmq1xxzr4Q-wY37=s64",
      "userId": "02067056678749702267"
     },
     "user_tz": -330
    },
    "id": "9Bcl7h2j_N_O",
    "jupyter": {
     "outputs_hidden": true
    },
    "new_sheet": false,
    "outputId": "aa47feb1-2bc5-4162-d5b4-5e986f84d936",
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 2048)              23587712  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 4098      \n",
      "=================================================================\n",
      "Total params: 23,591,810\n",
      "Trainable params: 4,098\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "id": "lqQeCLGy_N_T",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Next we compile our model using the **adam** optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "button": false,
    "colab": {},
    "colab_type": "code",
    "id": "4rlbL9b9_N_T",
    "jupyter": {
     "outputs_hidden": true
    },
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "id": "m03hCrOt_N_W",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Before we are able to start the training process, with an ImageDataGenerator, we will need to define how many steps compose an epoch. Typically, that is the number of images divided by the batch size. Therefore, we define our steps per epoch as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "button": false,
    "colab": {},
    "colab_type": "code",
    "id": "-nNX3ovg_N_X",
    "jupyter": {
     "outputs_hidden": true
    },
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "steps_per_epoch_training = len(train_generator)\n",
    "steps_per_epoch_validation = len(validation_generator)\n",
    "num_epochs = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "id": "Eclrw9lb_N_a",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Finally, we are ready to start training our model. Unlike a conventional deep learning training were data is not streamed from a directory, with an ImageDataGenerator where data is augmented in batches, we use the **fit_generator** method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "button": false,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 447849,
     "status": "ok",
     "timestamp": 1589614480932,
     "user": {
      "displayName": "Kota sai durga kamesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjTjqAs_XSPRluT1e_1a161LYmq1xxzr4Q-wY37=s64",
      "userId": "02067056678749702267"
     },
     "user_tz": -330
    },
    "id": "4fLZzqRN_N_a",
    "jupyter": {
     "outputs_hidden": true
    },
    "new_sheet": false,
    "outputId": "1a01d8b4-ffc3-4f02-ec95-cd7b31fade74",
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "301/301 [==============================] - 222s 738ms/step - loss: 0.0383 - accuracy: 0.9891 - val_loss: 0.5583 - val_accuracy: 0.8938\n",
      "Epoch 2/2\n",
      "301/301 [==============================] - 212s 704ms/step - loss: 0.0146 - accuracy: 0.9962 - val_loss: 1.6378e-04 - val_accuracy: 0.9312\n"
     ]
    }
   ],
   "source": [
    "fit_history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch_training,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=steps_per_epoch_validation,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 503671,
     "status": "ok",
     "timestamp": 1589615102511,
     "user": {
      "displayName": "Kota sai durga kamesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjTjqAs_XSPRluT1e_1a161LYmq1xxzr4Q-wY37=s64",
      "userId": "02067056678749702267"
     },
     "user_tz": -330
    },
    "id": "QmkWWb5haa3H",
    "outputId": "4ed3651c-3d51-4161-c386-e5b696d98ca6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "301/301 [==============================] - 214s 710ms/step - loss: 0.0129 - accuracy: 0.9965 - val_loss: 8.7377e-05 - val_accuracy: 0.9051\n",
      "Epoch 2/2\n",
      " 51/301 [====>.........................] - ETA: 2:06 - loss: 0.0053 - accuracy: 0.9986"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py:616: UserWarning: The input 15 could not be retrieved. It could be because a worker has died.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301/301 [==============================] - 289s 959ms/step - loss: 0.0070 - accuracy: 0.9981 - val_loss: 0.0016 - val_accuracy: 0.9388\n"
     ]
    }
   ],
   "source": [
    "fit_history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch_training,\n",
    "    epochs=2,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=steps_per_epoch_validation,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "id": "xRabQ25c_N_d",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Now that the model is trained, you are ready to start using it to classify images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "id": "AjTYHEt6_N_d",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Since training can take a long time when building deep learning models, it is always a good idea to save your model once the training is complete if you believe you will be using the model again later. You will be using this model in the next module, so go ahead and save your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "button": false,
    "colab": {},
    "colab_type": "code",
    "id": "ngTePPyg_N_e",
    "jupyter": {
     "outputs_hidden": true
    },
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model.save('classifier_resnet_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "id": "K37syosG_N_i",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Now, you should see the model file *classifier_resnet_model.h5* apprear in the left directory pane."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "id": "MYRF7mLh_N_j",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<hr>\n",
    "\n",
    "Copyright &copy; 2020 [IBM Developer Skills Network](https://cognitiveclass.ai/?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu). This notebook and its source code are released under the terms of the [MIT License](https://bigdatauniversity.com/mit-license/)."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Pretrained-Models.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
